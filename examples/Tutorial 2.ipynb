{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial: Create SDS from existing data set\n",
    "\n",
    "The SPARC Dataset Structure (SDS) is a standardised method for organising files and metadata. \n",
    "\n",
    "# Before you start:\n",
    "## Installing required modules\n",
    "pandas\n",
    "styleframe\n",
    "xlrd\n",
    "(other standard)\n",
    "\n",
    "In command prompt\n",
    "python -m pip\n",
    "\n",
    "pip install pandas\n",
    "pip install styleframe\n",
    "pip install xlrd\n",
    "\n",
    "    or\n",
    "    \n",
    "pip install -r /path/to/requirements.txt\n",
    "https://stackoverflow.com/questions/7225900/how-can-i-install-packages-using-pip-according-to-the-requirements-txt-file-from?rq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:\n",
      "code_description\n",
      "code_parameters\n",
      "dataset_description\n",
      "manifest\n",
      "performances\n",
      "resources\n",
      "samples\n",
      "subjects\n",
      "submission\n",
      "['code_description', 'code_parameters', 'dataset_description', 'manifest', 'performances', 'resources', 'samples', 'subjects', 'submission']\n",
      "Category: dataset_description\n",
      "Name\n",
      "    Type: Required\n",
      "    Description: Descriptive title for the data set. Equivalent to the title of a scientific paper. The metadata associated with the published version of this dataset does not currently make use of this field.\n",
      "    Example: My SPARC dataset\n",
      "Description\n",
      "    Type: Required\n",
      "    Description: NOTE This field is not currently used when publishing a SPARC dataset. Brief description of the study and the data set. Equivalent to the abstract of a scientific paper. Include the rationale for the approach, the types of data collected, the techniques used, formats and number of files and an approximate size. The metadata associated with the published version of this dataset does not currently make use of this field.\n",
      "    Example: A really cool dataset that I collected to answer some question.\n",
      "Keywords\n",
      "    Type: Required\n",
      "    Description: A set of 3-5 keywords other than the above that will aid in search\n",
      "    Example: spinal cord, electrophysiology, RNA-seq, mouse\n",
      "Contributors\n",
      "    Type: Required\n",
      "    Description: Name of any contributors to the dataset.  These individuals need not have been authors on any publications describing the data, but should be acknowledged for their role in producing and publishing the data set.  If more than one, add each contributor in a new column.\n",
      "    Example: Last, First Middle\n",
      "Contributor ORCID ID\n",
      "    Type: Required\n",
      "    Description: ORCID ID. If you don't have an ORCID, we suggest you sign up for one.\n",
      "    Example: https://orcid.org/0000-0002-5497-0243\n",
      "Contributor Affiliation\n",
      "    Type: Required\n",
      "    Description: Institutional affiliation for contributors\n",
      "    Example: https://ror.org/0168r3w48\n",
      "Contributor Role\n",
      "    Type: Required\n",
      "    Description: Contributor role, e.g., PrincipleInvestigator, Creator, CoInvestigator, ContactPerson, DataCollector, DataCurator, DataManager, Distributor, Editor, Producer, ProjectLeader, ProjectManager, ProjectMember, RelatedPerson, Researcher, ResearchGroup, Sponsor, Supervisor, WorkPackageLeader, Other.  These roles are provided by the Data Cite schema.  If more than one, add additional columns\n",
      "    Example: Data Collector\n",
      "Is Contact Person\n",
      "    Type: Required\n",
      "    Description: Yes or No if the contributor is a contact person for the dataset\n",
      "    Example: Yes\n",
      "Acknowledgements\n",
      "    Type: Required\n",
      "    Description: Acknowledgements beyond funding and contributors\n",
      "    Example: Thank you everyone!\n",
      "Funding\n",
      "    Type: Required\n",
      "    Description: Funding sources\n",
      "    Example: OT2OD025349\n",
      "Originating Article DOI\n",
      "    Type: Required\n",
      "    Description: DOIs of published articles that were generated from this dataset\n",
      "    Example: https://doi.org/10.13003/5jchdy\n",
      "Protocol URL or DOI\n",
      "    Type: Required\n",
      "    Description: URLs (if still private) / DOIs (if public) of protocols from protocols.io related to this dataset\n",
      "    Example: nan\n",
      "Additional Links\n",
      "    Type: Required\n",
      "    Description: URLs of additional resources used by this dataset (e.g., a link to a code repository)\n",
      "    Example: https://github.com/myuser/code-for-really-cool-data\n",
      "Link Description\n",
      "    Type: Required\n",
      "    Description: Short description of URL content, you do not need to fill this in for Originating Article DOI or Protocol URL or DOI \n",
      "    Example: link to GitHub repository for code used in this study\n",
      "Number of subjects\n",
      "    Type: Required\n",
      "    Description: Number of unique subjects in this dataset, should match subjects metadata file.\n",
      "    Example: 1\n",
      "Number of samples\n",
      "    Type: Required\n",
      "    Description: Number of unique samples in this dataset, should match samples metadata file. Set to zero if there are no samples.\n",
      "    Example: 0\n",
      "Completeness of data set\n",
      "    Type: Optional\n",
      "    Description: Is the data set as uploaded complete or is it part of an ongoing study.  Use \"hasNext\" to indicate that you expect more data on different subjects as a continuation of this study. Use “hasChildren” to indicate that you expect more data on the same subjects or samples derived from those subjects.\n",
      "    Example: hasNext, hasChildren\n",
      "Parent dataset ID\n",
      "    Type: Optional\n",
      "    Description: If this is a part of a larger data set, or refereces subjects or samples from a parent dataset, what was the accession number of the prior batch.  You need only give us the number of the last batch, not all batches. If samples and subjects are from multiple parent datasets please create a comma separated list of all parent ids.\n",
      "    Example: N:dataset:c5c2f40f-76be-4979-bfc4-b9f9947231cf\n",
      "Title for complete data set\n",
      "    Type: Optional\n",
      "    Description: Please give us a provisional title for the entire data set.\n",
      "    Example: nan\n",
      "Metadata Version DO NOT CHANGE\n",
      "    Type: Optional\n",
      "    Description: 1.2.3\n",
      "    Example: 1.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\Documents\\GitHub\\sparc-me\\sparc_me\\core\\dataset.py:430: FutureWarning:The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "from sparc_me import Dataset\n",
    "\n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "# List metadata categories/files\n",
    "categories = dataset.list_categories(version=\"2.0.0\")\n",
    "print(categories)\n",
    "\n",
    "# List elements/fields\n",
    "elements = dataset.list_elements(category=\"dataset_description\", version=\"2.0.0\")\n",
    "# elements = dataset.list_elements(category=\"subjects\", version=\"2.0.0\")\n",
    "\n",
    "# Creating/loading dataset\n",
    "\n",
    "# Load dataset from template. SPARC template datasets: https://github.com/SciCrunch/sparc-curation/releases\n",
    "dataset.load_from_template(version=\"2.0.0\")\n",
    "# dataset.load_dataset(from_template=True, version=\"2.0.0\")\n",
    "\n",
    "# Save the template dataset\n",
    "dataset.save(save_dir=\"./tmp/template/\")\n",
    "\n",
    "# Updating dataset\n",
    "\n",
    "# Update a metadata file.\n",
    "# Note: Excel index starts from 1 where index 1 is the header row. so actual data index starts from 2\n",
    "dataset.set_field(category=\"dataset_description\", row_index=2, header=\"Value\", value=\"testValue\")\n",
    "\n",
    "# # Append a row to the \"subjects\" metadata file. \"subject id\" will be set to \"test_id\"\n",
    "dataset.append(category=\"subjects\", row={\"subject id\": \"test_id\"})\n",
    "\n",
    "dataset.save(\"./tmp/template/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialise a dataset object\n",
    "from curses.ascii import isdigit\n",
    "from sparc_me import Dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "# Specify data location\n",
    "path=\"C:/Users/mhof485/Desktop/HSImages/*.png\"\n",
    "\n",
    "# Look through each file and sort into primary, derivative\n",
    "\n",
    "for fname in glob.glob(path):\n",
    "    name = fname.split(\"\\\\\")[1]    #get the name before file suffix\n",
    "    if name[0].isdigit():\n",
    "        ParticipantNumber = name[0]\n",
    "        if '_' in name:\n",
    "            dataset.add_derivative_data(fname, ParticipantNumber, \"s1\", \"sds_dataset\")  \n",
    "            # Here I am designating the file as derivative data, providing the participant number (obtained from the file name) \n",
    "            # and setting the sample number as \"s1\" as I know there was only one sample. \n",
    "                     \n",
    "        else:\n",
    "            dataset.add_primary_data(\"source_data_raw\", ParticipantNumber, \"s1\", sds_parent_dir=\"sds_dataset\")\n",
    "    \n",
    "\n",
    "# choose a template version for file structure\n",
    "\n",
    "dataset.set_template_version(version)\n",
    "\n",
    "\n",
    "# Populate with data\n",
    "\n",
    "###NEW FUNCTIONS REQUIRED###\n",
    "dataset.loadMetadata\n",
    "\n",
    "    # data provided should satisfy required fields of elements ()\n",
    "\n",
    "# Specify location to save data, now in SDS structure\n",
    "dataset.save(save_dir)\n",
    "\n",
    "# raw data -> primary\n",
    "\n",
    "# Processed data -> derivative\n",
    "\n",
    "##meta data - Dataset_description, Subjects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset_description: \n",
    "Spreadsheet listing basic details about the dataset included in the Details tab above.\n",
    "\n",
    "## Subjects: Spreadsheet \n",
    "listing subjects by their identifiers along with key details about subject characteristics, e.g., age, weight, and experimental groups.\n",
    "\n",
    "## Samples (if necessary): \n",
    "Spreadsheet listing specimens used in this study by their identifiers along with key details.\n",
    "\n",
    "## Readme: \n",
    "Investigators are encouraged to include a Readme file with important details necessary to understand the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Editing the metadata\n",
    "\n",
    "#Filter -> consider highlighting empty values before dropping\n",
    "dataset._filter(self, metadata, filename)\n",
    "\n",
    "#Inspect meta data\n",
    "dataset.list_categories(self, version)\n",
    "\n",
    "dataset.list_elements(self, category, axis=0, version=None)\n",
    "\n",
    "#Edit specific value\n",
    "dataset.set_field(self, category, row_index, header, value)\n",
    "\n",
    "\n",
    "#add entry - Append a row to a metadata file\n",
    "dataset.append(self, category, row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list.count() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\micha\\Documents\\GitHub\\sparc-me\\Tutorial 2.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/micha/Documents/GitHub/sparc-me/Tutorial%202.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(elements\u001b[39m.\u001b[39;49mcount())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/micha/Documents/GitHub/sparc-me/Tutorial%202.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m elements[\u001b[39m16\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: list.count() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "elements[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data to organise:\n",
    "C:\\Users\\micha\\OneDrive - The University of Auckland\\Uni\\PhD\\Experiments\\Fluorimeter\\dec 9\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a47e1e2c49c050a34b8a1fd5e73ef0ffb5353ba12db54c1637a8441d5d8b2e0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
