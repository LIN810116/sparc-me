{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e19748-b013-401c-8799-c394e8a7f22d",
   "metadata": {},
   "source": [
    "# sparc_me with o²S²PARC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b69f2ac",
   "metadata": {},
   "source": [
    "> o²S²PARC (also osparc) provides users with an interactive approach to effectively develop, extend, validate, certify, document, store, share, and apply models, explore the impact of stimulation parameters, and create predictive, multi-scale, multi-physics models for a wide range of scenarios -- [o²S²PARC docs](https://docs.osparc.io/#/docs/welcome/what_is_osparc)\n",
    "\n",
    "In a more simpler term, o²S²PARC gives user the capability to perform a wide variety of workflows on scientific data. Hence, it is important for sparc_me like libraries to work in synergy with o²S²PARC like platforms. \n",
    "\n",
    "In this tutorial, we are going through a simple usecase of sparc_me on o²S²PARC. We will;\n",
    "1. Create a [study](https://docs.osparc.io/#/docs/platform_introduction/studies)\n",
    "2. Add 3 [services (nodes)](https://docs.osparc.io/#/docs/platform_introduction/services): 2 File Picker nodes and 1 JupyterLab Math (Python+Octave) node\n",
    "3. Initialize File Picker nodes\n",
    "4. Add code in JupyterLab node to create an SDS structure dataset from File Picker inputs, using sparc_me\n",
    "5. Export JupyterLab created dataset as an output.zip, to be used in future nodes.\n",
    "\n",
    "Prerequisite:\n",
    "- o²S²PARC account\n",
    "- Zip sample1 and sample2 dummy data folders separately. They resides in sparc_me repository's [test_data section](https://github.com/SPARC-FAIR-Codeathon/sparc-me/tree/main/examples/test_data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b096b9e",
   "metadata": {},
   "source": [
    "## Creating the initial study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107c5d6d",
   "metadata": {},
   "source": [
    "![Outline of the study](https://github.com/SPARC-FAIR-Codeathon/sparc-me/blob/main/docs/images/osparc.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263a993",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. In the o²S²PARC dashboard, click on the `Empty Study` button\n",
    "2. In the resulting window, click `New node` button\n",
    "3. Pick `File picker` option from the list\n",
    "4. Drag and drop the sample1 zip file\n",
    "5. Repeat step 2,3 and 4 for sample2 zip file as well\n",
    "6. Click `New node` again and pick `JupyterLab Math (Python+Octave)` option from the list\n",
    "7. Connect the two File Picker nodes to the input port of JupyterLab node from GUI. (Connect the boxes representing the services using arrows from one port to another)\n",
    "8. Double click on JupyterLab node, and it will switch the view to the `Interactive` view. \n",
    "9. Create a new Jupyter notebook in your workspace and asign the Python kernal to it, when prompted.\n",
    "10. Add the following code to that notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e70a4",
   "metadata": {},
   "source": [
    "## sparc_me demo code to be run in o²S²PARC jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c03b9c-797d-416a-8106-d8bafb46904c",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to investigate the capabilities of Sparc-ME library in the context of O2S2PARC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be80dc8-4548-499c-9bff-67cdf531aa9e",
   "metadata": {},
   "source": [
    "### Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b64957f-44a3-45e5-9d05-550ee2ff08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757cc3e5-3b89-49f3-b58d-411e3be773a2",
   "metadata": {},
   "source": [
    "### Install sparc-me from PyPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b6ed58-1f66-4531-bf88-e7769a648d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install sparc_me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a192e05c-c42e-40a9-99a9-190f8a2ac706",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Accessing input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78179a23-126b-44a0-be74-2170d48dfd5c",
   "metadata": {},
   "source": [
    "The zip files you uploaded using the `file picker` will be automatically unzipped to the `../inputs/input_<number>/<zip-file-name>` directory. So now you have two separate directories:\n",
    "1. `../inputs/input_1/sample1`\n",
    "2. `../inputs/input_2/sample2`\n",
    "\n",
    "Now we are going to use sparc_me to create SDS dataset from these data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9850fcf",
   "metadata": {},
   "source": [
    "### Working with sparc_me in o²S²PARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee411767-6a1a-47c3-9bb9-c006ad9fefb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove when the pip sparc-me is available\n",
    "%cd sparc-me\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07cd8616-f21e-4ca3-b58f-f4e3cd055adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparc_me import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012efe02-36ef-41e0-85fa-ce3cd382b173",
   "metadata": {},
   "source": [
    "First, lets create the Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd26ce12-a237-4da7-afd5-fb174b924389",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefdeb62-427f-4a78-a00b-0636f31ab865",
   "metadata": {},
   "source": [
    "For the ease of access, lets define the source data paths. When we are doing automation tasks, we can iterate through inputs directory using `os.walk()` like methods and automatically do these kind of steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8099e23-5ede-4b6c-9727-a1a4681eb9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_subject_1_paths = [\"/home/jovyan/work/inputs/input_1/sample1/raw\", \"/home/jovyan/work/inputs/input_2/sample2/raw\"]\n",
    "derived_data_subject_1_paths = [\"/home/jovyan/work/inputs/input_1/sample1/derived\", \"/home/jovyan/work/inputs/input_2/sample2/derived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87351538-29e3-44ef-b152-cbbfcdba4c13",
   "metadata": {},
   "source": [
    "Now lets copy data from source directory to into a SDS structure directory. You don't have to manually create this. `sparc_me` will do the hard work for you! Just give a name for your directory. \n",
    "\n",
    "Another important thing is, when you are adding data through our library, the metadata modifications will be automatically handled for you.\n",
    "\n",
    "Also, for the purpose of demonstrating automation aspects, lets assume that sample ids are used as the directory names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ff91d3-7690-4e54-963e-6d110c6a4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SDS_DIR = \"sds_dataset\"\n",
    "\n",
    "# Copy raw data from source directory to SDS structured directory\n",
    "for path in raw_data_subject_1_paths:\n",
    "    sample_id = path.split('/')[-2]\n",
    "    dataset.add_primary_data(source_path=path,\n",
    "                             subject=\"subject-1\",\n",
    "                             sample=sample_id,\n",
    "                             sds_parent_dir=SDS_DIR\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007b31ed-55a0-4d14-9057-1f12b6a56ca8",
   "metadata": {},
   "source": [
    "We can perform similar functionality on derived data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "549608ce-4d28-4c01-8c81-aca6d9224bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copy derived data from source directory to derived directory in above created SDS structured directory\n",
    "for path in derived_data_subject_1_paths:\n",
    "    sample_id = path.split('/')[-2]\n",
    "    dataset.add_derivative_data(source_path=path,\n",
    "                                subject=\"subject-1\",\n",
    "                                sample=sample_id,\n",
    "                                sds_parent_dir=SDS_DIR\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d08eb-6771-404f-b8e5-c6105fac71a8",
   "metadata": {},
   "source": [
    "### Export created folder as a service output\n",
    "\n",
    "For another o²S²PARC service to be able to access the generated dataset, we have to export it as a service node output. This can simply be done by moving the created SDS structure dataset directory to `~/work/outputs/output_1` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f417d7-277c-4d56-91ce-f61a1a4b88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"/home/jovyan/work/outputs/output_1/sds_dataset\"\n",
    "shutil.copytree(src=SDS_DIR, dst=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcb651b-3e8f-4f50-90fa-71ef95cc102f",
   "metadata": {},
   "source": [
    "Now if we list the output_1 directory, we should be able to see out SDS structure dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2347880f-5dee-4946-8534-06997f4c1820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sds_dataset\n"
     ]
    }
   ],
   "source": [
    "!ls /home/jovyan/work/outputs/output_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sparc-me')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d915d484d29143458622af27531f243637148d4d1f40d48bbb4e8bcc5b37cd09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
