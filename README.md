# SPARC Metadata Editor (sparc-me)
A python tool to explore, enhance, and expand SPARC datasets and their descriptions

## About
This is the repository of Team sparc-me (Team #7) of the 2022 SPARC Codeathon. Click [here](https://sparc.science/help/2021-sparc-fair-codeathon) to find out more about the SPARC Codeathon 2022. Check out the Team section of this page to find out more about our team members.

## Introduction
The NIH Common Fund program on **[Stimulating Peripheral Activity to Relieve Conditions (SPARC)](https://commonfund.nih.gov/sparc) focuses on understanding peripheral nerves** (nerves that connect the brain and spinal cord to the rest of the body), **how their electrical signals control internal organ function**, and **how therapeutic devices could be developed to modulate electrical activity in nerves to improve organ function**. This may provide a potentially powerful way to treat a diverse set of common conditions and diseases such hypertension, heart failure, gastrointestinal disorders, and more. 60 research groups spanning 90 institutions and companies contribute to SPARC and work across over 15 organs and systems in 8 species.

**The [SPARC Portal](http://sparc.science/) provides a single user-facing online interface to all resources generated by the SPARC community** that can be shared, cited, visualized, computed, and used for virtual experimentation. A key offering of the portal is the collection of well-curated, high-impact data that is being generated by SPARC-funded researchers. These datasets, along with other SPARC projects and computational simulations, can be found under the "[Find Data](https://sparc.science/data?type=dataset)" section of the SPARC Portal. 

**A SPARC dataset comprises** the following data and structure:
- **An experimental protocol** that has been submitted to Protocols.io, shared with the SPARC working group, curated, and published with a valid DOI.
- **Data files are organized into folders** by the investigators and curated according to the [SPARC Dataset Structure (SDS)](https://docs.sparc.science/docs/overview-of-sparc-dataset-format) and stored on the [Pennsieve data management system](https://sparc.science/resources/2j9lC0YFl5P34wGlkJOb49). The SDS was adapted from the [Brain Imaging Data Structure (BIDS)](https://bids.neuroimaging.io/index.html) specification. Data organization and submission that is in compliance with the SDS is greatly simplified using a cross-platform opensource [Software to Organize Data Automatically (SODA)](https://docs.sodaforsparc.io/) through a step-by-step interactive graphical user interface (GUI).

## The problem
There is **currently no approach available**:
- for users to **programmatically access and interrogate all metadata fields in SDS datasets** from a scientific programming language such as python.
- for contributors to **programmatically create new SDS datasets** (schemas for the SDS dataset validation are not yet publicly available).

This requires attention, as it limits the ability of members of the SPARC and the wider scientific community to apply FAIR principles for:
- interacting with SDS datasets for conducting their research (**limits accessibilty**).
- reusing the SDS specification for storing and curating results from their instrumentation and computational physiology workflows (especially from automated workflows that can generate large quantities of data and multiple datasets that may be impractical to store in SDS format through a step-by-step interactive tools like SODA) (**limits reusability**).
- quickly prototyping novel infrastructure/tools to elevate the impact of the SPARC program.  (**limits application**)
- propose and support extensions to the SDS ([similar to BIDS extensions](https://bids.neuroimaging.io/get_involved.html#extending-the-bids-specification) to further expand the SPARC community e.g. by storing clinical data (**limits interoperabilty**)

## Our solution - sparc-me
To address this problem, we have **developed a python module called the SPARC Metadata Editor (sparc-me)** that can be used to enhance the FAIRness of SPARC data by enabling:

- *Discovery*
  - Accessing curated SDS datasets and their metadata (using the Pennsieve API)
  - Accessing protocols used by existing SDS datasets (using the protocols.io API)
  - Exploring data and metadata within SDS datasets
  - Defining a schema for SDS datasets
- *Interaction*
  - Creating, editing, and validating SDS datasets
- *Reusability and extensibilty*
  - Version controlling SDS schemas
- *Interoperabilty*
  - Conversion between BIDS datasets and SDS datasets

Examples and guided tutorials have been created to demonstrate each of the features above. 

## Use-cases of sparc-me
Potential application scenarios for sparc-me are illustrated in the figure below.


## Impact
sparc-me will elevate the impact of the SPARC program by providing the fundamental tools needed by users to programmatically interact with SDS datasets and efficiently build novel resources and tools from SPARC data. This includes:
- **supporting proposed [SPARC Data and Resource Centre (DRC)](https://docs.sparc.science/docs/getting-started) and communnity developments** including:
  - assisting with efforts for automating SPARC data curation e.g. via realtime/on-the-fly dataset validation by users prior submission for curation.
  - improving efficiency of software developments (e.g. future codeathons and [SPARC portal roadmap developments](https://docs.sparc.science/docs/sparc-portal-roadmap)) by reducing the need to reimplement common functions. 
- **supporting and promoting reuse/harmonisation/compatibility with other research initiatives**. For example, sparc-me could be used to programatically map SDS descriptions to [Gen3 data dictionaries](https://gen3.org/resources/user/dictionary/) used in other NIH-funded initiatives such as the Common Fundâ€™s [NIH Data Commons program](https://commonfund.nih.gov/commons).
 - **enabling version-controlled extensions of the SDS specification** to be proposed/explored (similar to BIDS extensions). This will enable other initiatives to build upon the extensive and ground-breaking developments of the SPARC community e.g. for storing results from [computational physiology workflows and digital twins that are being developed for precision medicine](https://doi.org/10.52843/cassyni.m56qzg).

## Using sparc-me
### From source code
#### Pre-requisites 
- [Git](https://git-scm.com/)
#### Installing

Downloading source code
```
git clone https://github.com/SPARC-FAIR-Codeathon/sparc-me.git
```

Installing dependencies
```
pip install -r requirements.txt
```

#### Running the examples

A base example is located in ./examples/base_example.py for loading/saving/editing dataset/metadata 

### Tutorials

Guided tutorials have been developed for the following application scenarios to demonstrate how to use the tool:
-Tutorial 1 - demonstrates how to:
  a. programmatically download an existing curated SDS dataset ([human whole-body computational scaffold with embedded organs](10.26275/fvsg-hzg1)).
  b. use existing tools to query ontology terms that have been used to annotate SDS datasets using the SciCrunch knowledgebase.
- Tutorial 2 - programmatically create an SDS dataset from input data from a jet-injection experiment.
- Tutorial 3 - create a version-controlled extension of the SDS to include additional metadata fields, and apply it to the dataset considered in Tutorial 1 to include data use descriptions from the GA4GH-approved Data Use Ontology (DUO). This tutorial is a first step toward demonstrating how the SDS could be extended to describe clinical data.
- Tutorial 4 - Interacting with SDS datasets on O2SPARC with sparc-me.
- Tutorial 5 - Converting a BIDS dataset to a SDS dataset.

