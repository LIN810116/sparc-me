# sparc-me
Enhance and expand the SPARC dataset metadata

## About
This is the repository of Team sparc-me (Team #7) of the 2022 SPARC Codeathon. Click [here](https://sparc.science/help/2021-sparc-fair-codeathon) to find out more about the SPARC Codeathon 2022. Check out the Team section of this page to find out more about our team members.

## The problem
The NIH Common Fund program on [Stimulating Peripheral Activity to Relieve Conditions (SPARC)](https://commonfund.nih.gov/sparc) focuses on understanding peripheral nerves (nerves that connect the brain and spinal cord to the rest of the body), how their electrical signals control internal organ function, and how therapeutic devices could be developed to modulate electrical activity in nerves to improve organ function. This may provide a potentially powerful way to treat a diverse set of common conditions and diseases such hypertension, heart failure, gastrointestinal disorders, and more. 60 research groups spanning 90 institutions and companies contribute to SPARC and work across over 15 organs and systems in 8 species.

The [SPARC Portal](http://sparc.science/) provides a single user-facing online interface to all resources generated by the SPARC community that can be shared, cited, visualized, computed, and used for virtual experimentation. A key offering of the portal is the collection of well-curated, high-impact data that is being generated by SPARC-funded researchers. These datasets, along with other SPARC projects and computational simulations, can be found under the "[Find Data](https://sparc.science/data?type=dataset)" section of the SPARC Portal. 

A SPARC dataset comprises the following data and structure:
An experimental protocol that has been submitted to Protocols.io, shared with the SPARC working group, curated, and published with a valid DOI.
Data files are organized into folders by the investigators and curated according to the [SPARC Dataset Structure (SDS)](https://docs.sparc.science/docs/overview-of-sparc-dataset-format). The SDS was adapted from the [Brain Imaging Data Structure (BIDS)](https://bids.neuroimaging.io/index.html) specification. Data organization and submission that is in compliance with the SDS is greatly simplified using a cross-platform opensource [Software to Organize Data Automatically (SODA)](https://docs.sodaforsparc.io/) through a step-by-step interactive graphical user interface (GUI).

However, there is currently no approach available:
- for users to access and interrogate data and metadata in existing datasets on the SPARC portal from scientific programming languages such as python.
- for contributors to programmatically create new SDS datasets (schemas for the SDS are not yet publicly available for dataset validation).

This requires attention, as it limits the ability of members of the SPARC and the wider scientific community to apply FAIR principles to:
- interact with SDS datasets for conducting their research (Accessibilty).
- reuse the SDS specification for storing and curating results from their computational physiology workflows (especially from automated workflows that can generate large quantities of data in multiple datasets that may be impractical to store in SDS format through a step-by-step interactive tool like SODA) (Reusability).
- quickly prototype novel infrastructure/tools that can make use of the data to help further expand the SPARC community and elevate the impact of the SPARC program (Reusability/Interoperabilty)
- propose and support extensions to the SDS (similar to BIDS extensions) e.g. to store clinical data (Interoperabilty)

## Our solution - sparc-me
To address this problem, we have developed a python module called the SPARC Metadata Editor (sparc-me). sparc-me enables:

- Discovery
  - Access existing SDS datasets on the SPARC portal using the Pennsieve API
  - Access protocols used by existing SDS datasets on the SPARC portal using the protocols.io API
  - Access data and metadata within SDS datasets
  - Derive a schema for SDS datasets
- Interaction
  - Creating SDS datasets
  - Editing SDS datasets
  - Validating SDS datasets
- Extension
  - Version controlling SDS schemas
Conversion
  - Converting BIDS datasets to SDS datasets
  - Converting SDS datasets to BIDS datasets

Examples have been created to demonstrate each of the features above. 

## Impact
sparc-me will help provide the fundamental tools needed by users to programmatically interact with SDS datasets to:
- support proposed developments on the SPARC portal roadmap
  - Assisting with SPARC data curation including increasing automation of data and model submissions via realtime/on-the-fly validation by users)
  - Provide tools that can be used to support and promote reuse/harmonisation/compatibility with other research initiatives. For example, sparc-me could be used to programatically map SDS descriptions to Gen3 data dictionaries used in other NIH-funded initiatives such as the Common Fundâ€™s NIH Data Commons program.
- enable other SPARC DRC infrastructure developments (e.g. by using sparc-me in backends).
- improve the efficiency of future code-a-thons organised by SPARC.
- elevate the impact of the SPARC program by enabling version-controlled extensions of the SDS description to be proposed/explored (similar to BIDS extensions). This will enable other initiatives to build upon the extensive and ground-breaking developments of the SPARC community e.g. for storing results from computational physiology workflows and digital twins that are being developed for precision medicine.

## Using sparc-me
### From source code
#### Pre-requisites 
- [Git](https://git-scm.com/)
#### Installing

Downloading source code
```
git clone https://github.com/SPARC-FAIR-Codeathon/sparc-me.git
```

Installing dependencies
```
pip install -r requirements.txt
```

#### Running the examples

A base example is located in ./examples/base_example.py for loading/saving/editing dataset/metadata 
